<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>deeplearning on tkat0.github.io</title>
    <link>https://tkat0.github.io/tags/deeplearning/</link>
    <description>Recent content in deeplearning on tkat0.github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 07 Jul 2019 06:30:00 +0900</lastBuildDate>
    
	<atom:link href="https://tkat0.github.io/tags/deeplearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[1907.01989] On-Device Neural Net Inference with Mobile GPUs</title>
      <link>https://tkat0.github.io/posts/1907.01989/</link>
      <pubDate>Sun, 07 Jul 2019 06:30:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/1907.01989/</guid>
      <description>&lt;p&gt;Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>GoogleのMediaPipeでMLアプリ開発が楽になる</title>
      <link>https://tkat0.github.io/posts/mediapipe/</link>
      <pubDate>Wed, 19 Jun 2019 06:30:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/mediapipe/</guid>
      <description>&lt;p&gt;GoogleがMediaPipeを公開。 エッジもサーバーも、MLを組み込んだアプリケーションを作るのが楽になりそうだ。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ONNXRuntime調査</title>
      <link>https://tkat0.github.io/posts/read-onnxruntime/</link>
      <pubDate>Wed, 22 May 2019 09:00:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/read-onnxruntime/</guid>
      <description>&lt;p&gt;ONNXモデルの推論エンジン。TensorRTのpreviewが出ると。この機会にちょっと調べる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Distillerの検証環境をDockerで作った</title>
      <link>https://tkat0.github.io/posts/docker-env-for-distiller/</link>
      <pubDate>Fri, 22 Feb 2019 11:00:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/docker-env-for-distiller/</guid>
      <description>&lt;p&gt;PyTorch向けの軽量化ライブラリである&lt;a href=&#34;https://github.com/NervanaSystems/distiller&#34;&gt;Distiller&lt;/a&gt;を触る環境をDockerで作っただけの話&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chainer-compiler調査（2）</title>
      <link>https://tkat0.github.io/posts/learn-chainer-compiler-2/</link>
      <pubDate>Wed, 06 Feb 2019 09:30:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/learn-chainer-compiler-2/</guid>
      <description>&lt;p&gt;Chainer-compilerの調査その2&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>PyTorchのModule#named_modules</title>
      <link>https://tkat0.github.io/posts/pytorch-named_modules/</link>
      <pubDate>Wed, 06 Feb 2019 08:30:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/pytorch-named_modules/</guid>
      <description>&lt;p&gt;PyTorchのModule#named_modulesでモデル内のすべてのOperatorにアクセスするときにはまったメモ。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chainer-compiler調査（1）</title>
      <link>https://tkat0.github.io/posts/learn-chainer-compiler-1/</link>
      <pubDate>Mon, 04 Feb 2019 09:30:00 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/learn-chainer-compiler-1/</guid>
      <description>&lt;p&gt;今日からChainer-compilerについて調べてみよう。 DeepLearningコンパイラ、先日の&lt;a href=&#34;https://fpgax.connpass.com/event/115446/&#34;&gt;FPGAX&lt;/a&gt;でも話題になってましたね（リモートでちょっと見てました）&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>いまさらONNXを調べた(v1.4.1)</title>
      <link>https://tkat0.github.io/posts/learn-onnx/</link>
      <pubDate>Sat, 02 Feb 2019 13:00:01 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/learn-onnx/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://onnx.ai/&#34;&gt;ONNX&lt;/a&gt;は1年以上前から使ってるもののちゃんと仕様しらないな〜、だったので調べた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Distillerのthinningの仕様</title>
      <link>https://tkat0.github.io/posts/distiller-thinning/</link>
      <pubDate>Sat, 02 Feb 2019 12:00:01 +0900</pubDate>
      
      <guid>https://tkat0.github.io/posts/distiller-thinning/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/NervanaSystems/distiller&#34;&gt;Distiller&lt;/a&gt;はPytorch向けのpruningやquantizationを行うライブラリだが、Channel Pruning後にWeightをshrinkしてサイズを小さくする&amp;quot;thinning&amp;quot;ができる。
今回はそのソースを読んで気がついたことのまとめ。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>