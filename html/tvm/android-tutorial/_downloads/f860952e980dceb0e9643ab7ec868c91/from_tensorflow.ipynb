{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nCompile Tensorflow Models\n=========================\nThis article is an introductory tutorial to deploy tensorflow models with TVM.\n\nFor us to begin with, tensorflow python module is required to be installed.\n\nPlease refer to https://www.tensorflow.org/install\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# tvm, relay\nimport tvm\nfrom tvm import relay\n\n# os and numpy\nimport numpy as np\nimport os.path\n\n# Tensorflow imports\nimport tensorflow as tf\n\n# Tensorflow utility functions\nimport tvm.relay.testing.tf as tf_testing\n\n# Base location for model related files.\nrepo_base = 'https://github.com/dmlc/web-data/raw/master/tensorflow/models/InceptionV1/'\n\n# Test image\nimg_name = 'elephant-299.jpg'\nimage_url = os.path.join(repo_base, img_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tutorials\n---------\nPlease refer docs/frontend/tensorflow.md for more details for various models\nfrom tensorflow.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_name = 'classify_image_graph_def-with_shapes.pb'\nmodel_url = os.path.join(repo_base, model_name)\n\n# Image label map\nmap_proto = 'imagenet_2012_challenge_label_map_proto.pbtxt'\nmap_proto_url = os.path.join(repo_base, map_proto)\n\n# Human readable text for labels\nlabel_map = 'imagenet_synset_to_human_label_map.txt'\nlabel_map_url = os.path.join(repo_base, label_map)\n\n# Target settings\n# Use these commented settings to build for cuda.\n#target = 'cuda'\n#target_host = 'llvm'\n#layout = \"NCHW\"\n#ctx = tvm.gpu(0)\ntarget = 'llvm'\ntarget_host = 'llvm'\nlayout = None\nctx = tvm.cpu(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download required files\n-----------------------\nDownload files listed above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib.download import download_testdata\n\nimg_path = download_testdata(image_url, img_name, module='data')\nmodel_path = download_testdata(model_url, model_name, module=['tf', 'InceptionV1'])\nmap_proto_path = download_testdata(map_proto_url, map_proto, module='data')\nlabel_path = download_testdata(label_map_url, label_map, module='data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import model\n------------\nCreates tensorflow graph definition from protobuf file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with tf.gfile.FastGFile(model_path, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    graph = tf.import_graph_def(graph_def, name='')\n    # Call the utility to import the graph definition into default graph.\n    graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n    # Add shapes to the graph.\n    with tf.Session() as sess:\n        graph_def = tf_testing.AddShapesToGraphDef(sess, 'softmax')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decode image\n------------\n<div class=\"alert alert-info\"><h4>Note</h4><p>tensorflow frontend import doesn't support preprocessing ops like JpegDecode.\n  JpegDecode is bypassed (just return source node).\n  Hence we supply decoded frame to TVM instead.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from PIL import Image\nimage = Image.open(img_path).resize((299, 299))\n\nx = np.array(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the graph to Relay\n-------------------------\nImport tensorflow graph definition to relay frontend.\n\nResults:\n  sym: relay expr for given tensorflow protobuf.\n  params: params converted from tensorflow params (tensor protobuf).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "shape_dict = {'DecodeJpeg/contents': x.shape}\ndtype_dict = {'DecodeJpeg/contents': 'uint8'}\nsym, params = relay.frontend.from_tensorflow(graph_def, layout=layout, shape=shape_dict)\n\nprint(\"Tensorflow protobuf imported to relay frontend.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Relay Build\n-----------\nCompile the graph to llvm target with given input specification.\n\nResults:\n  graph: Final graph after compilation.\n  params: final params after compilation.\n  lib: target library which can be deployed on target with tvm runtime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with relay.build_config(opt_level=3):\n    graph, lib, params = relay.build(sym, target=target, target_host=target_host, params=params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Execute the portable graph on TVM\n---------------------------------\nNow we can try deploying the compiled model on target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from tvm.contrib import graph_runtime\ndtype = 'uint8'\nm = graph_runtime.create(graph, lib, ctx)\n# set inputs\nm.set_input('DecodeJpeg/contents', tvm.nd.array(x.astype(dtype)))\nm.set_input(**params)\n# execute\nm.run()\n# get outputs\ntvm_output = m.get_output(0, tvm.nd.empty(((1, 1008)), 'float32'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Process the output\n------------------\nProcess the model output to human readable text for InceptionV1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = tvm_output.asnumpy()\npredictions = np.squeeze(predictions)\n\n# Creates node ID --> English string lookup.\nnode_lookup = tf_testing.NodeLookup(label_lookup_path=map_proto_path,\n                                    uid_lookup_path=label_path)\n\n# Print top 5 predictions from TVM output.\ntop_k = predictions.argsort()[-5:][::-1]\nfor node_id in top_k:\n    human_string = node_lookup.id_to_string(node_id)\n    score = predictions[node_id]\n    print('%s (score = %.5f)' % (human_string, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inference on tensorflow\n-----------------------\nRun the corresponding model on tensorflow\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_graph():\n    \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\n    # Creates graph from saved graph_def.pb.\n    with tf.gfile.FastGFile(model_path, 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        graph = tf.import_graph_def(graph_def, name='')\n        # Call the utility to import the graph definition into default graph.\n        graph_def = tf_testing.ProcessGraphDefParam(graph_def)\n\ndef run_inference_on_image(image):\n    \"\"\"Runs inference on an image.\n\n    Parameters\n    ----------\n    image: String\n        Image file name.\n\n    Returns\n    -------\n        Nothing\n    \"\"\"\n    if not tf.gfile.Exists(image):\n        tf.logging.fatal('File does not exist %s', image)\n    image_data = tf.gfile.FastGFile(image, 'rb').read()\n\n    # Creates graph from saved GraphDef.\n    create_graph()\n\n    with tf.Session() as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n        predictions = sess.run(softmax_tensor,\n                               {'DecodeJpeg/contents:0': image_data})\n\n        predictions = np.squeeze(predictions)\n\n        # Creates node ID --> English string lookup.\n        node_lookup = tf_testing.NodeLookup(label_lookup_path=map_proto_path,\n                                            uid_lookup_path=label_path)\n\n        # Print top 5 predictions from tensorflow.\n        top_k = predictions.argsort()[-5:][::-1]\n        print (\"===== TENSORFLOW RESULTS =======\")\n        for node_id in top_k:\n            human_string = node_lookup.id_to_string(node_id)\n            score = predictions[node_id]\n            print('%s (score = %.5f)' % (human_string, score))\n\nrun_inference_on_image(img_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}