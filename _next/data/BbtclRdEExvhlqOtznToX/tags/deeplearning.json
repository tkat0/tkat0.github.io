{"pageProps":{"posts":[{"title":"[1907.01989] On-Device Neural Net Inference with Mobile GPUs","date":"2019-07-06T21:30:00.000Z","tags":["tflite","deeplearning","paper"],"summary":"Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。","slug":"1907.01989","locale":"ja","type":"Blog","readingTime":{"text":"7 min read","minutes":6.035,"time":362100,"words":1207},"path":"posts/1907.01989","filePath":"posts/201906/1907.01989.mdx","toc":[]},{"title":"GoogleのMediaPipeでMLアプリ開発が楽になる","date":"2019-06-18T21:30:00.000Z","tags":["mediapipe","deeplearning"],"summary":"GoogleがMediaPipeを公開。 エッジもサーバーも、MLを組み込んだアプリケーションを作るのが楽になりそうだ。","slug":"mediapipe","locale":"ja","type":"Blog","readingTime":{"text":"4 min read","minutes":3.865,"time":231900,"words":773},"path":"posts/mediapipe","filePath":"posts/201906/mediapipe.mdx","toc":[]},{"title":"Distillerのthinningの仕様","date":"2019-02-02T03:00:01.000Z","tags":["distiller","deeplearning","pruning"],"summary":"DistillerはPytorch向けのpruningやquantizationを行うライブラリだが、Channel Pruning後にWeightをshrinkしてサイズを小さくする\"thinning\"ができる。\n今回はそのソースを読んで気がついたことのまとめ。","slug":"distiller-thinning","locale":"ja","type":"Blog","readingTime":{"text":"3 min read","minutes":3,"time":180000,"words":600},"path":"posts/distiller-thinning","filePath":"posts/201902/distiller-thinning.mdx","toc":[]},{"title":"Chainer-compiler調査（1）","date":"2019-02-04T00:30:00.000Z","tags":["chainer-compiler","deeplearning","chainer"],"summary":"今日からChainer-compilerについて調べてみよう。","slug":"learn-chainer-compiler-1","locale":"ja","type":"Blog","readingTime":{"text":"6 min read","minutes":5.59,"time":335400,"words":1118},"path":"posts/learn-chainer-compiler-1","filePath":"posts/201902/learn-chainer-compiler-1.mdx","toc":[{"value":"Examples","url":"#examples","depth":2},{"value":"Overview of components","url":"#overview-of-components","depth":2},{"value":"chainer-compiler/python","url":"#chainer-compilerpython","depth":2},{"value":"次にやりたいこと","url":"#次にやりたいこと","depth":2}]},{"title":"Chainer-compiler調査（2）","date":"2019-02-06T00:30:00.000Z","tags":["chainer-compiler","deeplearning","chainer"],"summary":"Chainer-compilerの調査その2","slug":"learn-chainer-compiler-2","locale":"ja","type":"Blog","readingTime":{"text":"3 min read","minutes":2.515,"time":150900,"words":503},"path":"posts/learn-chainer-compiler-2","filePath":"posts/201902/learn-chainer-compiler-2.mdx","toc":[{"value":"examples/train_mnist.py","url":"#examplestrain_mnistpy","depth":2},{"value":"CompiledModel#forward","url":"#compiledmodelforward","depth":2},{"value":"CompiledModel#compile","url":"#compiledmodelcompile","depth":2},{"value":"RunCompiledModel#forward","url":"#runcompiledmodelforward","depth":2},{"value":"その他","url":"#その他","depth":2}]},{"title":"いまさらONNXを調べた(v1.4.1)","date":"2019-02-02T04:00:01.000Z","tags":["onnx","deeplearning"],"summary":"ONNXは1年以上前から使ってるもののちゃんと仕様しらないな〜、だったので調べた。","slug":"learn-onnx","locale":"ja","type":"Blog","readingTime":{"text":"6 min read","minutes":5.48,"time":328800,"words":1096},"path":"posts/learn-onnx","filePath":"posts/201902/learn-onnx.mdx","toc":[{"value":"onnx.proto","url":"#onnxproto","depth":2},{"value":"Versioning","url":"#versioning","depth":2},{"value":"ONNX Optimizer","url":"#onnx-optimizer","depth":2},{"value":"TypeDenotation","url":"#typedenotation","depth":2}]},{"title":"PyTorchのModule#named_modules","date":"2019-02-05T23:30:00.000Z","tags":["pytorch","deeplearning"],"summary":"PyTorchのModule#named_modulesでモデル内のすべてのOperatorにアクセスするときにはまったメモ。","slug":"pytorch-named_modules","locale":"ja","type":"Blog","readingTime":{"text":"2 min read","minutes":1.05,"time":63000,"words":210},"path":"posts/pytorch-named_modules","filePath":"posts/201902/pytorch-named_modules.mdx","toc":[]},{"title":"ONNXRuntime調査","date":"2019-05-22T00:00:00.000Z","tags":["onnxruntime","deeplearning","onnx","tvm"],"summary":"ONNXモデルの推論エンジン。TensorRTのpreviewが出ると。この機会にちょっと調べる。","slug":"read-onnxruntime","locale":"ja","type":"Blog","readingTime":{"text":"2 min read","minutes":1.945,"time":116700,"words":389},"path":"posts/read-onnxruntime","filePath":"posts/201903/read-onnxruntime.mdx","toc":[{"value":"Usage","url":"#usage","depth":2},{"value":"Design and Key Features","url":"#design-and-key-features","depth":2},{"value":"その他 1","url":"#その他-1","depth":2},{"value":"その他 2","url":"#その他-2","depth":2}]},{"title":"Distillerの検証環境をDockerで作った","date":"2019-02-22T02:00:00.000Z","tags":["distiller","pytorch","docker","deeplearning","pruning"],"summary":"PyTorch向けの軽量化ライブラリであるDistillerを触る環境をDockerで作っただけの話","slug":"docker-env-for-distiller","locale":"ja","type":"Blog","readingTime":{"text":"3 min read","minutes":2.53,"time":151800,"words":506},"path":"posts/docker-env-for-distiller","filePath":"posts/201902/docker-env-for-distiller/index.mdx","toc":[]},{"title":"WebAssemblyでの機械学習モデルデプロイの動向","date":"2020-12-02T10:30:00.000Z","tags":["rust","wasm","deeplearning","mlops"],"draft":false,"summary":"本記事はMLOps Advent Calendar 2020の2日目の記事です。\nこの記事では、機械学習モデル（特にDeep Learning）をWasmでデプロイする周辺技術の動向や内部の仕組みをざっくりと説明します。","slug":"deploy-ml-as-wasm","locale":"ja","type":"Blog","readingTime":{"text":"18 min read","minutes":17.725,"time":1063500,"words":3545},"path":"posts/deploy-ml-as-wasm","filePath":"posts/202012/deploy-ml-as-wasm/index.mdx","toc":[{"value":"WebAssembly(Wasm) とは","url":"#webassemblywasm-とは","depth":2},{"value":"Wasm を機械学習で使うモチベーション","url":"#wasm-を機械学習で使うモチベーション","depth":2},{"value":"Wasm の機械学習モデルデプロイの動向","url":"#wasm-の機械学習モデルデプロイの動向","depth":2},{"value":"ブラウザへのデプロイ","url":"#ブラウザへのデプロイ","depth":3},{"value":"サーバーサイドへのデプロイ","url":"#サーバーサイドへのデプロイ","depth":3},{"value":"エッジデバイスへのデプロイ","url":"#エッジデバイスへのデプロイ","depth":3},{"value":"各プロジェクトの Wasm 対応状況","url":"#各プロジェクトの-wasm-対応状況","depth":2},{"value":"TensorFlow","url":"#tensorflow","depth":3},{"value":"TVM","url":"#tvm","depth":3},{"value":"WASI-NN","url":"#wasi-nn","depth":3},{"value":"ONNC-WASM","url":"#onnc-wasm","depth":3},{"value":"その他","url":"#その他","depth":3},{"value":"結論","url":"#結論","depth":2},{"value":"おまけ","url":"#おまけ","depth":2}]}],"tag":"deeplearning"},"__N_SSG":true}