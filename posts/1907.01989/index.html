<!DOCTYPE html><html lang="ja-jp" class="scroll-smooth"><head><meta charSet="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/><title>[1907.01989] On-Device Neural Net Inference with Mobile GPUs</title><meta name="robots" content="follow, index"/><meta name="description" content="Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。"/><meta property="og:url" content="https://tkat0.dev//posts/1907.01989/"/><meta property="og:type" content="article"/><meta property="og:site_name" content="tkat0.dev"/><meta property="og:description" content="Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。"/><meta property="og:title" content="[1907.01989] On-Device Neural Net Inference with Mobile GPUs"/><meta property="og:image" content="https://tkat0.dev//static/images/twitter-card.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="https://twitter.com/_tkato_"/><meta name="twitter:title" content="[1907.01989] On-Device Neural Net Inference with Mobile GPUs"/><meta name="twitter:description" content="Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。"/><meta name="twitter:image" content="https://tkat0.dev//static/images/twitter-card.png"/><link rel="canonical" href="https://tkat0.dev//posts/1907.01989/"/><meta property="article:published_time" content="2019-07-06T21:30:00.000Z"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tkat0.dev//posts/1907.01989"
  },
  "headline": "[1907.01989] On-Device Neural Net Inference with Mobile GPUs",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://tkat0.dev//static/images/twitter-card.png"
    }
  ],
  "datePublished": "2019-07-06T21:30:00.000Z",
  "dateModified": "2019-07-06T21:30:00.000Z",
  "author": {
    "@type": "Person",
    "name": "tkat0"
  },
  "publisher": {
    "@type": "Organization",
    "name": "tkat0",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tkat0.dev//static/images/tkat0.jpg"
    }
  },
  "description": "Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。"
}</script><meta name="next-head-count" content="19"/><link rel="apple-touch-icon" sizes="76x76" href="/static/favicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><meta name="msapplication-TileColor" content="#000000"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fff"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preload" href="/_next/static/media/2aaf0723e720e8b9.p.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/7079befd3a2cd672.css" as="style"/><link rel="stylesheet" href="/_next/static/css/7079befd3a2cd672.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-70df5622b4020830.js" defer=""></script><script src="/_next/static/chunks/framework-3b5a00d5d7e8d93b.js" defer=""></script><script src="/_next/static/chunks/main-63d7f848a4309603.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6a9774580a51b196.js" defer=""></script><script src="/_next/static/chunks/896-f5176a3de761310c.js" defer=""></script><script src="/_next/static/chunks/447-6d81102f1475f3cd.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5B...slug%5D-989a64eb0543fe6c.js" defer=""></script><script src="/_next/static/BbtclRdEExvhlqOtznToX/_buildManifest.js" defer=""></script><script src="/_next/static/BbtclRdEExvhlqOtznToX/_ssgManifest.js" defer=""></script></head><body class="bg-white text-black antialiased dark:bg-gray-900 dark:text-white"><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><section class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="__className_9c9965 flex h-screen flex-col justify-between font-sans"><header class="flex items-center justify-between py-10"><div><a aria-label="tkat0.dev" href="/"><div class="flex items-center justify-between"><div class="mr-3"><img alt="avatar" src="/static/images/tkat0.jpg" width="48" height="48" decoding="async" data-nimg="1" class="rounded-full" loading="lazy" style="color:transparent"/></div><div class="h-6 text-2xl font-semibold">tkat0.dev</div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/posts/">Blog</a><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/tags/">Tags</a><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/about/">About</a></div><a class="rounded-lg border-2 border-gray-700 p-1 dark:border-gray-200" href="/en/posts/1907.01989">EN</a><button aria-label="Toggle Dark Mode" class="ml-1 mr-1 h-8 w-8 rounded p-1 sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button class="ml-1 mr-1 h-8 w-8 rounded py-1" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed top-0 left-0 z-10 h-full w-full transform bg-gray-200 opacity-95 duration-300 ease-in-out dark:bg-gray-800 translate-x-full"><div class="flex justify-end"><button class="mr-5 mt-11 h-8 w-8 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><nav class="fixed mt-8 h-full"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/posts/">Blog</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/tags/">Tags</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/about/">About</a></div></nav></div></div></div></header><main class="mb-auto"><section class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="fixed right-8 bottom-8 hidden flex-col gap-3 md:hidden"><button aria-label="Scroll To Comment" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M18 10c0 3.866-3.582 7-8 7a8.841 8.841 0 01-4.083-.98L2 17l1.338-3.123C2.493 12.767 2 11.434 2 10c0-3.866 3.582-7 8-7s8 3.134 8 7zM7 9H5v2h2V9zm8 0h-2v2h2V9zM9 9h2v2H9V9z" clip-rule="evenodd"></path></svg></button><button aria-label="Scroll To Top" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg></button></div><article><div><header><div class="space-y-1 border-b border-gray-200 pb-10 text-center dark:border-gray-700"><dl><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2019-07-06T21:30:00.000Z">2019年7月7日</time></dd></div></dl><div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">[1907.01989] On-Device Neural Net Inference with Mobile GPUs</h1></div></div></header><div class="grid-rows-[auto_1fr] divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:divide-y-0"><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0"><div class="prose max-w-none pt-10 pb-8 dark:prose-dark"><p>Google Research より、TFLite GPU のアーキテクチャ設計についての論文。</p><ul><li>1907.01989 On-Device Neural Net Inference with Mobile GPUs</li><li>tensorflow/tensorflow/lite/delegates/gpu at master · tensorflow/tensorflow · GitHub</li></ul><p>ざっとまとめると、</p><ul><li>モバイル CPU で NN の推論は難しい<ul><li>計算量、熱、バッテリー</li><li>特に既存のロジックが CPU で動いてるのに、そこに計算負荷を追加すると…</li><li>実際、Fig8 で iPhone XS の MobileNetV1 の CPU 推論、3 分ちょいで熱でパフォーマンス落ちてる</li></ul></li><li>モバイル GPU を NN の推論に使う<ul><li>NPU などのアクセラレータ、一部のハイエンド機しかないよね</li><li>多くのデバイスをターゲットとするために GPU</li><li>モデルにもよるが、TFLite の CPU→GPU で x2-9 は速くなる</li></ul></li><li>TFLite GPU のデザイン<ul><li>vendor specific な実装を避け、OpenGL や Metal をバックエンドとした<ul><li>OpenCL はサポートしてない端末多いよね</li></ul></li><li>delegate<ul><li>GPU オフロード可能なサブグラフをまとめて、delegate node</li><li>それ以外は CPU</li></ul></li><li>最適化<ul><li>コマンド数やメモリ IO を少なくするため、よくある最適化はしている</li><li>コードだとこの辺のモジュール</li><li>tensorflow/fuse_inline.cc at 46252f3 · tensorflow/tensorflow · GitHub</li><li>operator fusion</li><li>意味のない命令は消す（x1 のリサイズとか）</li><li>パラメータをシェーダにインライン化</li><li>ドライバでの最適化も期待し、TFLite としてはあくまでコードを出力</li><li>一部のシェーダは人手で最適化</li></ul></li><li>データレイアウト<ul><li>モバイル GPU は、文字通りグラフィクス用途に適した 4 要素のベクトル（x,y,z,w）の計算や読み書きに特化</li><li>これに合わせて NN も計算しないと遅いので、HWC のテンソルも C を 4 チャネル単位で分解して、PHWC4 と呼ぶレイアウトにしている</li><li>（TFLite じゃないフレームワークでも、この”4”で pack/unpack はよく見る気がする</li><li>CHW-&gt;PHWC4 への変換の実装<ul><li>tensorflow/tensorflow/lite/delegates/gpu/gl/converters at 46252f3 · tensorflow/tensorflow · GitHub</li></ul></li></ul></li><li>WorkGroup 数の決め方<ul><li>GPU によって、WorkGroup 数のチューニングのシビアさが変わる<ul><li>Mali はチューニング頑張っても 5%程度しか向上しないが、Adreno は 30％向上する場合も</li></ul></li><li>総当たりで調べるのは、デバイスの状態（熱など）にもよるので、必ずしも最適解は得にくい</li><li>そこで推論時間の関数を勾配法で最適化して、デバイスや属性ごとにいくつかのセットをつくってるみたい<ul><li>最適化部分のコードはわからないけど、結果は以下のようにディスパッチ<ul><li>tensorflow/conv.cc at 46252f3 · tensorflow/tensorflow · GitHub</li><li>tensorflow/default_calculator.cc at 46252f3 · tensorflow/tensorflow · GitHub</li></ul></li></ul></li></ul></li><li>メモリ管理<ul><li>メモリのフットプリントを小さくするため、中間テンソルをいつ確保するか</li><li>Greedy と MCFP の 2 つのアルゴリズムを実装<ul><li>（詳細はよんでないけど、<ul><li>中間テンソルは使い回す前提で、最大サイズでアロケートしておき、使いまわせるタイミングで使い回す（雑な理解</li></ul></li><li>モデルにより良し悪しが変わるのでデフォルト Greedy</li><li>ただナイーブな実装よりは MB 単位で数倍は軽くなる</li></ul></li></ul></li></ul></li><li>実験<ul><li>iOS は、CoreML より TFLite GPU が総じて速い<ul><li>（これなんでだろう？</li></ul></li><li>Android は、vendor specific なフレームワーク（SNPE(Qualcomm)）より 2 倍程度遅いケースもある<ul><li>それより多くの端末で動くほうが嬉しいよねという感じ</li><li>（MACE（Xiaomi）、こんど使ってみるかーと思ってたけど、これなら TFLite のほうが良さそう…</li></ul></li></ul></li></ul><p>TFLite の実装はちゃんと見てないけど、この論文で説明がある構成になってるんだろう。 MediaPipe など見ていると、スマホ AR などで TFLite を使って様々なアプリケーションを高速に世に出していきたいんだろうなーと思えていて、それを実現する技術として、この選択肢をとったかと思うと面白い。</p><p>Table5、Android 端末で TFLite GPU と MACE（Xiaomi）、SNPE（Qualcomm）を比較してるんだけど、 この速度差ならどっちのフレームワークをつかう？ってのは人によって判断が変わりそうで面白い。 数倍の遅延も許容できない、かつ、サポートしたいプラットフォームがすくなければ、vendor specific なフレームワークでもいいかもしれない。</p><p>しかし、新しいアーキテクチャがでたとか、BlazeFace のように 7x7 がいいよみたいなときに、実際に早く速く動かせるものはどれ？と考えると、 Research→Deployment までのエコシステムの充実度、ベンダーに依存しない拡張の早さが見込めるなどで TFLite を選択するモチベーションは大きいんじゃないかな。</p><p>実装はちら見した程度だけど、カーネルの実装の中にも GpuType::ADRENO とかでてきて、やっぱり避けられないよなーという感じ。</p><p>合わせて読みたい論文としては以下。</p><p><a target="_blank" rel="noopener noreferrer" href="https://research.fb.com/publications/machine-learning-at-facebook-understanding-inference-at-the-edge/">Machine Learning at Facebook: Understanding Inference at the Edge - Facebook Research</a></p></div></div><div class="pt-6 pb-6 text-center text-gray-700 dark:text-gray-300" id="comment"><div class="giscus"></div></div><footer><div class="flex flex-col text-sm font-medium sm:flex-row sm:justify-between sm:text-base"><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" aria-label="Previous post: neon-bindings/neonについて" href="/posts/neon-bindings/">← <!-- -->neon-bindings/neonについて</a></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" aria-label="Next post: WebAssemblyでの機械学習モデルデプロイの動向" href="/posts/deploy-ml-as-wasm/">WebAssemblyでの機械学習モデルデプロイの動向<!-- --> →</a></div></div></footer></div></div></article></section></main><footer><div class="mt-16 flex flex-col items-center"><div class="mb-3 flex space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/tkat0"><span class="sr-only">github</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/tkat0/"><span class="sr-only">linkedin</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://twitter.com/_tkato_"><span class="sr-only">twitter</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a></div><div class="mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>tkat0</div><div> • </div><div>© 2023</div><div> • </div><a href="/">tkat0.dev</a></div><div class="mb-8 text-sm text-gray-500 dark:text-gray-400"><a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a></div></div></footer></div></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"[1907.01989] On-Device Neural Net Inference with Mobile GPUs","date":"2019-07-06T21:30:00.000Z","tags":["tflite","deeplearning","paper"],"summary":"Google Researchより、TFLite GPUのアーキテクチャ設計についての論文。","slug":"1907.01989","locale":"ja","body":{"raw":"\nGoogle Research より、TFLite GPU のアーキテクチャ設計についての論文。\n\n- 1907.01989 On-Device Neural Net Inference with Mobile GPUs\n- tensorflow/tensorflow/lite/delegates/gpu at master · tensorflow/tensorflow · GitHub\n\nざっとまとめると、\n\n- モバイル CPU で NN の推論は難しい\n  - 計算量、熱、バッテリー\n  - 特に既存のロジックが CPU で動いてるのに、そこに計算負荷を追加すると…\n  - 実際、Fig8 で iPhone XS の MobileNetV1 の CPU 推論、3 分ちょいで熱でパフォーマンス落ちてる\n- モバイル GPU を NN の推論に使う\n  - NPU などのアクセラレータ、一部のハイエンド機しかないよね\n  - 多くのデバイスをターゲットとするために GPU\n  - モデルにもよるが、TFLite の CPU→GPU で x2-9 は速くなる\n- TFLite GPU のデザイン\n  - vendor specific な実装を避け、OpenGL や Metal をバックエンドとした\n    - OpenCL はサポートしてない端末多いよね\n  - delegate\n    - GPU オフロード可能なサブグラフをまとめて、delegate node\n    - それ以外は CPU\n  - 最適化\n    - コマンド数やメモリ IO を少なくするため、よくある最適化はしている\n    - コードだとこの辺のモジュール\n    - tensorflow/fuse_inline.cc at 46252f3 · tensorflow/tensorflow · GitHub\n    - operator fusion\n    - 意味のない命令は消す（x1 のリサイズとか）\n    - パラメータをシェーダにインライン化\n    - ドライバでの最適化も期待し、TFLite としてはあくまでコードを出力\n    - 一部のシェーダは人手で最適化\n  - データレイアウト\n    - モバイル GPU は、文字通りグラフィクス用途に適した 4 要素のベクトル（x,y,z,w）の計算や読み書きに特化\n    - これに合わせて NN も計算しないと遅いので、HWC のテンソルも C を 4 チャネル単位で分解して、PHWC4 と呼ぶレイアウトにしている\n    - （TFLite じゃないフレームワークでも、この”4”で pack/unpack はよく見る気がする\n    - CHW-\u003ePHWC4 への変換の実装\n      - tensorflow/tensorflow/lite/delegates/gpu/gl/converters at 46252f3 · tensorflow/tensorflow · GitHub\n  - WorkGroup 数の決め方\n    - GPU によって、WorkGroup 数のチューニングのシビアさが変わる\n      - Mali はチューニング頑張っても 5%程度しか向上しないが、Adreno は 30％向上する場合も\n    - 総当たりで調べるのは、デバイスの状態（熱など）にもよるので、必ずしも最適解は得にくい\n    - そこで推論時間の関数を勾配法で最適化して、デバイスや属性ごとにいくつかのセットをつくってるみたい\n      - 最適化部分のコードはわからないけど、結果は以下のようにディスパッチ\n        - tensorflow/conv.cc at 46252f3 · tensorflow/tensorflow · GitHub\n        - tensorflow/default_calculator.cc at 46252f3 · tensorflow/tensorflow · GitHub\n  - メモリ管理\n    - メモリのフットプリントを小さくするため、中間テンソルをいつ確保するか\n    - Greedy と MCFP の 2 つのアルゴリズムを実装\n      - （詳細はよんでないけど、\n        - 中間テンソルは使い回す前提で、最大サイズでアロケートしておき、使いまわせるタイミングで使い回す（雑な理解\n      - モデルにより良し悪しが変わるのでデフォルト Greedy\n      - ただナイーブな実装よりは MB 単位で数倍は軽くなる\n- 実験\n  - iOS は、CoreML より TFLite GPU が総じて速い\n    - （これなんでだろう？\n  - Android は、vendor specific なフレームワーク（SNPE(Qualcomm)）より 2 倍程度遅いケースもある\n    - それより多くの端末で動くほうが嬉しいよねという感じ\n    - （MACE（Xiaomi）、こんど使ってみるかーと思ってたけど、これなら TFLite のほうが良さそう…\n\nTFLite の実装はちゃんと見てないけど、この論文で説明がある構成になってるんだろう。 MediaPipe など見ていると、スマホ AR などで TFLite を使って様々なアプリケーションを高速に世に出していきたいんだろうなーと思えていて、それを実現する技術として、この選択肢をとったかと思うと面白い。\n\nTable5、Android 端末で TFLite GPU と MACE（Xiaomi）、SNPE（Qualcomm）を比較してるんだけど、 この速度差ならどっちのフレームワークをつかう？ってのは人によって判断が変わりそうで面白い。 数倍の遅延も許容できない、かつ、サポートしたいプラットフォームがすくなければ、vendor specific なフレームワークでもいいかもしれない。\n\nしかし、新しいアーキテクチャがでたとか、BlazeFace のように 7x7 がいいよみたいなときに、実際に早く速く動かせるものはどれ？と考えると、 Research→Deployment までのエコシステムの充実度、ベンダーに依存しない拡張の早さが見込めるなどで TFLite を選択するモチベーションは大きいんじゃないかな。\n\n実装はちら見した程度だけど、カーネルの実装の中にも GpuType::ADRENO とかでてきて、やっぱり避けられないよなーという感じ。\n\n合わせて読みたい論文としては以下。\n\n[Machine Learning at Facebook: Understanding Inference at the Edge - Facebook Research](https://research.fb.com/publications/machine-learning-at-facebook-understanding-inference-at-the-edge/)\n","code":"var Component=(()=\u003e{var s=Object.create;var c=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var f=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,G=Object.prototype.hasOwnProperty;var P=(i,e)=\u003e()=\u003e(e||i((e={exports:{}}).exports,e),e.exports),g=(i,e)=\u003e{for(var n in e)c(i,n,{get:e[n],enumerable:!0})},t=(i,e,n,d)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let r of f(e))!G.call(i,r)\u0026\u0026r!==n\u0026\u0026c(i,r,{get:()=\u003ee[r],enumerable:!(d=u(e,r))||d.enumerable});return i};var w=(i,e,n)=\u003e(n=i!=null?s(p(i)):{},t(e||!i||!i.__esModule?c(n,\"default\",{value:i,enumerable:!0}):n,i)),m=i=\u003et(c({},\"__esModule\",{value:!0}),i);var o=P((M,h)=\u003e{h.exports=_jsx_runtime});var L={};g(L,{default:()=\u003eC,frontmatter:()=\u003eU});var l=w(o()),U={title:\"[1907.01989] On-Device Neural Net Inference with Mobile GPUs\",date:new Date(15624486e5),slug:\"1907.01989\",tags:[\"tflite\",\"deeplearning\",\"paper\"],summary:\"Google Research\\u3088\\u308A\\u3001TFLite GPU\\u306E\\u30A2\\u30FC\\u30AD\\u30C6\\u30AF\\u30C1\\u30E3\\u8A2D\\u8A08\\u306B\\u3064\\u3044\\u3066\\u306E\\u8AD6\\u6587\\u3002\"};function a(i){let e=Object.assign({p:\"p\",ul:\"ul\",li:\"li\",a:\"a\"},i.components);return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(e.p,{children:\"Google Research \\u3088\\u308A\\u3001TFLite GPU \\u306E\\u30A2\\u30FC\\u30AD\\u30C6\\u30AF\\u30C1\\u30E3\\u8A2D\\u8A08\\u306B\\u3064\\u3044\\u3066\\u306E\\u8AD6\\u6587\\u3002\"}),(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"1907.01989 On-Device Neural Net Inference with Mobile GPUs\"}),(0,l.jsx)(e.li,{children:\"tensorflow/tensorflow/lite/delegates/gpu at master \\xB7 tensorflow/tensorflow \\xB7 GitHub\"})]}),(0,l.jsx)(e.p,{children:\"\\u3056\\u3063\\u3068\\u307E\\u3068\\u3081\\u308B\\u3068\\u3001\"}),(0,l.jsxs)(e.ul,{children:[(0,l.jsxs)(e.li,{children:[\"\\u30E2\\u30D0\\u30A4\\u30EB CPU \\u3067 NN \\u306E\\u63A8\\u8AD6\\u306F\\u96E3\\u3057\\u3044\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"\\u8A08\\u7B97\\u91CF\\u3001\\u71B1\\u3001\\u30D0\\u30C3\\u30C6\\u30EA\\u30FC\"}),(0,l.jsx)(e.li,{children:\"\\u7279\\u306B\\u65E2\\u5B58\\u306E\\u30ED\\u30B8\\u30C3\\u30AF\\u304C CPU \\u3067\\u52D5\\u3044\\u3066\\u308B\\u306E\\u306B\\u3001\\u305D\\u3053\\u306B\\u8A08\\u7B97\\u8CA0\\u8377\\u3092\\u8FFD\\u52A0\\u3059\\u308B\\u3068\\u2026\"}),(0,l.jsx)(e.li,{children:\"\\u5B9F\\u969B\\u3001Fig8 \\u3067 iPhone XS \\u306E MobileNetV1 \\u306E CPU \\u63A8\\u8AD6\\u30013 \\u5206\\u3061\\u3087\\u3044\\u3067\\u71B1\\u3067\\u30D1\\u30D5\\u30A9\\u30FC\\u30DE\\u30F3\\u30B9\\u843D\\u3061\\u3066\\u308B\"})]})]}),(0,l.jsxs)(e.li,{children:[\"\\u30E2\\u30D0\\u30A4\\u30EB GPU \\u3092 NN \\u306E\\u63A8\\u8AD6\\u306B\\u4F7F\\u3046\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"NPU \\u306A\\u3069\\u306E\\u30A2\\u30AF\\u30BB\\u30E9\\u30EC\\u30FC\\u30BF\\u3001\\u4E00\\u90E8\\u306E\\u30CF\\u30A4\\u30A8\\u30F3\\u30C9\\u6A5F\\u3057\\u304B\\u306A\\u3044\\u3088\\u306D\"}),(0,l.jsx)(e.li,{children:\"\\u591A\\u304F\\u306E\\u30C7\\u30D0\\u30A4\\u30B9\\u3092\\u30BF\\u30FC\\u30B2\\u30C3\\u30C8\\u3068\\u3059\\u308B\\u305F\\u3081\\u306B GPU\"}),(0,l.jsx)(e.li,{children:\"\\u30E2\\u30C7\\u30EB\\u306B\\u3082\\u3088\\u308B\\u304C\\u3001TFLite \\u306E CPU\\u2192GPU \\u3067 x2-9 \\u306F\\u901F\\u304F\\u306A\\u308B\"})]})]}),(0,l.jsxs)(e.li,{children:[\"TFLite GPU \\u306E\\u30C7\\u30B6\\u30A4\\u30F3\",(0,l.jsxs)(e.ul,{children:[(0,l.jsxs)(e.li,{children:[\"vendor specific \\u306A\\u5B9F\\u88C5\\u3092\\u907F\\u3051\\u3001OpenGL \\u3084 Metal \\u3092\\u30D0\\u30C3\\u30AF\\u30A8\\u30F3\\u30C9\\u3068\\u3057\\u305F\",(0,l.jsx)(e.ul,{children:(0,l.jsx)(e.li,{children:\"OpenCL \\u306F\\u30B5\\u30DD\\u30FC\\u30C8\\u3057\\u3066\\u306A\\u3044\\u7AEF\\u672B\\u591A\\u3044\\u3088\\u306D\"})})]}),(0,l.jsxs)(e.li,{children:[\"delegate\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"GPU \\u30AA\\u30D5\\u30ED\\u30FC\\u30C9\\u53EF\\u80FD\\u306A\\u30B5\\u30D6\\u30B0\\u30E9\\u30D5\\u3092\\u307E\\u3068\\u3081\\u3066\\u3001delegate node\"}),(0,l.jsx)(e.li,{children:\"\\u305D\\u308C\\u4EE5\\u5916\\u306F CPU\"})]})]}),(0,l.jsxs)(e.li,{children:[\"\\u6700\\u9069\\u5316\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"\\u30B3\\u30DE\\u30F3\\u30C9\\u6570\\u3084\\u30E1\\u30E2\\u30EA IO \\u3092\\u5C11\\u306A\\u304F\\u3059\\u308B\\u305F\\u3081\\u3001\\u3088\\u304F\\u3042\\u308B\\u6700\\u9069\\u5316\\u306F\\u3057\\u3066\\u3044\\u308B\"}),(0,l.jsx)(e.li,{children:\"\\u30B3\\u30FC\\u30C9\\u3060\\u3068\\u3053\\u306E\\u8FBA\\u306E\\u30E2\\u30B8\\u30E5\\u30FC\\u30EB\"}),(0,l.jsx)(e.li,{children:\"tensorflow/fuse_inline.cc at 46252f3 \\xB7 tensorflow/tensorflow \\xB7 GitHub\"}),(0,l.jsx)(e.li,{children:\"operator fusion\"}),(0,l.jsx)(e.li,{children:\"\\u610F\\u5473\\u306E\\u306A\\u3044\\u547D\\u4EE4\\u306F\\u6D88\\u3059\\uFF08x1 \\u306E\\u30EA\\u30B5\\u30A4\\u30BA\\u3068\\u304B\\uFF09\"}),(0,l.jsx)(e.li,{children:\"\\u30D1\\u30E9\\u30E1\\u30FC\\u30BF\\u3092\\u30B7\\u30A7\\u30FC\\u30C0\\u306B\\u30A4\\u30F3\\u30E9\\u30A4\\u30F3\\u5316\"}),(0,l.jsx)(e.li,{children:\"\\u30C9\\u30E9\\u30A4\\u30D0\\u3067\\u306E\\u6700\\u9069\\u5316\\u3082\\u671F\\u5F85\\u3057\\u3001TFLite \\u3068\\u3057\\u3066\\u306F\\u3042\\u304F\\u307E\\u3067\\u30B3\\u30FC\\u30C9\\u3092\\u51FA\\u529B\"}),(0,l.jsx)(e.li,{children:\"\\u4E00\\u90E8\\u306E\\u30B7\\u30A7\\u30FC\\u30C0\\u306F\\u4EBA\\u624B\\u3067\\u6700\\u9069\\u5316\"})]})]}),(0,l.jsxs)(e.li,{children:[\"\\u30C7\\u30FC\\u30BF\\u30EC\\u30A4\\u30A2\\u30A6\\u30C8\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"\\u30E2\\u30D0\\u30A4\\u30EB GPU \\u306F\\u3001\\u6587\\u5B57\\u901A\\u308A\\u30B0\\u30E9\\u30D5\\u30A3\\u30AF\\u30B9\\u7528\\u9014\\u306B\\u9069\\u3057\\u305F 4 \\u8981\\u7D20\\u306E\\u30D9\\u30AF\\u30C8\\u30EB\\uFF08x,y,z,w\\uFF09\\u306E\\u8A08\\u7B97\\u3084\\u8AAD\\u307F\\u66F8\\u304D\\u306B\\u7279\\u5316\"}),(0,l.jsx)(e.li,{children:\"\\u3053\\u308C\\u306B\\u5408\\u308F\\u305B\\u3066 NN \\u3082\\u8A08\\u7B97\\u3057\\u306A\\u3044\\u3068\\u9045\\u3044\\u306E\\u3067\\u3001HWC \\u306E\\u30C6\\u30F3\\u30BD\\u30EB\\u3082 C \\u3092 4 \\u30C1\\u30E3\\u30CD\\u30EB\\u5358\\u4F4D\\u3067\\u5206\\u89E3\\u3057\\u3066\\u3001PHWC4 \\u3068\\u547C\\u3076\\u30EC\\u30A4\\u30A2\\u30A6\\u30C8\\u306B\\u3057\\u3066\\u3044\\u308B\"}),(0,l.jsx)(e.li,{children:\"\\uFF08TFLite \\u3058\\u3083\\u306A\\u3044\\u30D5\\u30EC\\u30FC\\u30E0\\u30EF\\u30FC\\u30AF\\u3067\\u3082\\u3001\\u3053\\u306E\\u201D4\\u201D\\u3067 pack/unpack \\u306F\\u3088\\u304F\\u898B\\u308B\\u6C17\\u304C\\u3059\\u308B\"}),(0,l.jsxs)(e.li,{children:[\"CHW-\u003ePHWC4 \\u3078\\u306E\\u5909\\u63DB\\u306E\\u5B9F\\u88C5\",(0,l.jsx)(e.ul,{children:(0,l.jsx)(e.li,{children:\"tensorflow/tensorflow/lite/delegates/gpu/gl/converters at 46252f3 \\xB7 tensorflow/tensorflow \\xB7 GitHub\"})})]})]})]}),(0,l.jsxs)(e.li,{children:[\"WorkGroup \\u6570\\u306E\\u6C7A\\u3081\\u65B9\",(0,l.jsxs)(e.ul,{children:[(0,l.jsxs)(e.li,{children:[\"GPU \\u306B\\u3088\\u3063\\u3066\\u3001WorkGroup \\u6570\\u306E\\u30C1\\u30E5\\u30FC\\u30CB\\u30F3\\u30B0\\u306E\\u30B7\\u30D3\\u30A2\\u3055\\u304C\\u5909\\u308F\\u308B\",(0,l.jsx)(e.ul,{children:(0,l.jsx)(e.li,{children:\"Mali \\u306F\\u30C1\\u30E5\\u30FC\\u30CB\\u30F3\\u30B0\\u9811\\u5F35\\u3063\\u3066\\u3082 5%\\u7A0B\\u5EA6\\u3057\\u304B\\u5411\\u4E0A\\u3057\\u306A\\u3044\\u304C\\u3001Adreno \\u306F 30\\uFF05\\u5411\\u4E0A\\u3059\\u308B\\u5834\\u5408\\u3082\"})})]}),(0,l.jsx)(e.li,{children:\"\\u7DCF\\u5F53\\u305F\\u308A\\u3067\\u8ABF\\u3079\\u308B\\u306E\\u306F\\u3001\\u30C7\\u30D0\\u30A4\\u30B9\\u306E\\u72B6\\u614B\\uFF08\\u71B1\\u306A\\u3069\\uFF09\\u306B\\u3082\\u3088\\u308B\\u306E\\u3067\\u3001\\u5FC5\\u305A\\u3057\\u3082\\u6700\\u9069\\u89E3\\u306F\\u5F97\\u306B\\u304F\\u3044\"}),(0,l.jsxs)(e.li,{children:[\"\\u305D\\u3053\\u3067\\u63A8\\u8AD6\\u6642\\u9593\\u306E\\u95A2\\u6570\\u3092\\u52FE\\u914D\\u6CD5\\u3067\\u6700\\u9069\\u5316\\u3057\\u3066\\u3001\\u30C7\\u30D0\\u30A4\\u30B9\\u3084\\u5C5E\\u6027\\u3054\\u3068\\u306B\\u3044\\u304F\\u3064\\u304B\\u306E\\u30BB\\u30C3\\u30C8\\u3092\\u3064\\u304F\\u3063\\u3066\\u308B\\u307F\\u305F\\u3044\",(0,l.jsx)(e.ul,{children:(0,l.jsxs)(e.li,{children:[\"\\u6700\\u9069\\u5316\\u90E8\\u5206\\u306E\\u30B3\\u30FC\\u30C9\\u306F\\u308F\\u304B\\u3089\\u306A\\u3044\\u3051\\u3069\\u3001\\u7D50\\u679C\\u306F\\u4EE5\\u4E0B\\u306E\\u3088\\u3046\\u306B\\u30C7\\u30A3\\u30B9\\u30D1\\u30C3\\u30C1\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"tensorflow/conv.cc at 46252f3 \\xB7 tensorflow/tensorflow \\xB7 GitHub\"}),(0,l.jsx)(e.li,{children:\"tensorflow/default_calculator.cc at 46252f3 \\xB7 tensorflow/tensorflow \\xB7 GitHub\"})]})]})})]})]})]}),(0,l.jsxs)(e.li,{children:[\"\\u30E1\\u30E2\\u30EA\\u7BA1\\u7406\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"\\u30E1\\u30E2\\u30EA\\u306E\\u30D5\\u30C3\\u30C8\\u30D7\\u30EA\\u30F3\\u30C8\\u3092\\u5C0F\\u3055\\u304F\\u3059\\u308B\\u305F\\u3081\\u3001\\u4E2D\\u9593\\u30C6\\u30F3\\u30BD\\u30EB\\u3092\\u3044\\u3064\\u78BA\\u4FDD\\u3059\\u308B\\u304B\"}),(0,l.jsxs)(e.li,{children:[\"Greedy \\u3068 MCFP \\u306E 2 \\u3064\\u306E\\u30A2\\u30EB\\u30B4\\u30EA\\u30BA\\u30E0\\u3092\\u5B9F\\u88C5\",(0,l.jsxs)(e.ul,{children:[(0,l.jsxs)(e.li,{children:[\"\\uFF08\\u8A73\\u7D30\\u306F\\u3088\\u3093\\u3067\\u306A\\u3044\\u3051\\u3069\\u3001\",(0,l.jsx)(e.ul,{children:(0,l.jsx)(e.li,{children:\"\\u4E2D\\u9593\\u30C6\\u30F3\\u30BD\\u30EB\\u306F\\u4F7F\\u3044\\u56DE\\u3059\\u524D\\u63D0\\u3067\\u3001\\u6700\\u5927\\u30B5\\u30A4\\u30BA\\u3067\\u30A2\\u30ED\\u30B1\\u30FC\\u30C8\\u3057\\u3066\\u304A\\u304D\\u3001\\u4F7F\\u3044\\u307E\\u308F\\u305B\\u308B\\u30BF\\u30A4\\u30DF\\u30F3\\u30B0\\u3067\\u4F7F\\u3044\\u56DE\\u3059\\uFF08\\u96D1\\u306A\\u7406\\u89E3\"})})]}),(0,l.jsx)(e.li,{children:\"\\u30E2\\u30C7\\u30EB\\u306B\\u3088\\u308A\\u826F\\u3057\\u60AA\\u3057\\u304C\\u5909\\u308F\\u308B\\u306E\\u3067\\u30C7\\u30D5\\u30A9\\u30EB\\u30C8 Greedy\"}),(0,l.jsx)(e.li,{children:\"\\u305F\\u3060\\u30CA\\u30A4\\u30FC\\u30D6\\u306A\\u5B9F\\u88C5\\u3088\\u308A\\u306F MB \\u5358\\u4F4D\\u3067\\u6570\\u500D\\u306F\\u8EFD\\u304F\\u306A\\u308B\"})]})]})]})]})]})]}),(0,l.jsxs)(e.li,{children:[\"\\u5B9F\\u9A13\",(0,l.jsxs)(e.ul,{children:[(0,l.jsxs)(e.li,{children:[\"iOS \\u306F\\u3001CoreML \\u3088\\u308A TFLite GPU \\u304C\\u7DCF\\u3058\\u3066\\u901F\\u3044\",(0,l.jsx)(e.ul,{children:(0,l.jsx)(e.li,{children:\"\\uFF08\\u3053\\u308C\\u306A\\u3093\\u3067\\u3060\\u308D\\u3046\\uFF1F\"})})]}),(0,l.jsxs)(e.li,{children:[\"Android \\u306F\\u3001vendor specific \\u306A\\u30D5\\u30EC\\u30FC\\u30E0\\u30EF\\u30FC\\u30AF\\uFF08SNPE(Qualcomm)\\uFF09\\u3088\\u308A 2 \\u500D\\u7A0B\\u5EA6\\u9045\\u3044\\u30B1\\u30FC\\u30B9\\u3082\\u3042\\u308B\",(0,l.jsxs)(e.ul,{children:[(0,l.jsx)(e.li,{children:\"\\u305D\\u308C\\u3088\\u308A\\u591A\\u304F\\u306E\\u7AEF\\u672B\\u3067\\u52D5\\u304F\\u307B\\u3046\\u304C\\u5B09\\u3057\\u3044\\u3088\\u306D\\u3068\\u3044\\u3046\\u611F\\u3058\"}),(0,l.jsx)(e.li,{children:\"\\uFF08MACE\\uFF08Xiaomi\\uFF09\\u3001\\u3053\\u3093\\u3069\\u4F7F\\u3063\\u3066\\u307F\\u308B\\u304B\\u30FC\\u3068\\u601D\\u3063\\u3066\\u305F\\u3051\\u3069\\u3001\\u3053\\u308C\\u306A\\u3089 TFLite \\u306E\\u307B\\u3046\\u304C\\u826F\\u3055\\u305D\\u3046\\u2026\"})]})]})]})]})]}),(0,l.jsx)(e.p,{children:\"TFLite \\u306E\\u5B9F\\u88C5\\u306F\\u3061\\u3083\\u3093\\u3068\\u898B\\u3066\\u306A\\u3044\\u3051\\u3069\\u3001\\u3053\\u306E\\u8AD6\\u6587\\u3067\\u8AAC\\u660E\\u304C\\u3042\\u308B\\u69CB\\u6210\\u306B\\u306A\\u3063\\u3066\\u308B\\u3093\\u3060\\u308D\\u3046\\u3002 MediaPipe \\u306A\\u3069\\u898B\\u3066\\u3044\\u308B\\u3068\\u3001\\u30B9\\u30DE\\u30DB AR \\u306A\\u3069\\u3067 TFLite \\u3092\\u4F7F\\u3063\\u3066\\u69D8\\u3005\\u306A\\u30A2\\u30D7\\u30EA\\u30B1\\u30FC\\u30B7\\u30E7\\u30F3\\u3092\\u9AD8\\u901F\\u306B\\u4E16\\u306B\\u51FA\\u3057\\u3066\\u3044\\u304D\\u305F\\u3044\\u3093\\u3060\\u308D\\u3046\\u306A\\u30FC\\u3068\\u601D\\u3048\\u3066\\u3044\\u3066\\u3001\\u305D\\u308C\\u3092\\u5B9F\\u73FE\\u3059\\u308B\\u6280\\u8853\\u3068\\u3057\\u3066\\u3001\\u3053\\u306E\\u9078\\u629E\\u80A2\\u3092\\u3068\\u3063\\u305F\\u304B\\u3068\\u601D\\u3046\\u3068\\u9762\\u767D\\u3044\\u3002\"}),(0,l.jsx)(e.p,{children:\"Table5\\u3001Android \\u7AEF\\u672B\\u3067 TFLite GPU \\u3068 MACE\\uFF08Xiaomi\\uFF09\\u3001SNPE\\uFF08Qualcomm\\uFF09\\u3092\\u6BD4\\u8F03\\u3057\\u3066\\u308B\\u3093\\u3060\\u3051\\u3069\\u3001 \\u3053\\u306E\\u901F\\u5EA6\\u5DEE\\u306A\\u3089\\u3069\\u3063\\u3061\\u306E\\u30D5\\u30EC\\u30FC\\u30E0\\u30EF\\u30FC\\u30AF\\u3092\\u3064\\u304B\\u3046\\uFF1F\\u3063\\u3066\\u306E\\u306F\\u4EBA\\u306B\\u3088\\u3063\\u3066\\u5224\\u65AD\\u304C\\u5909\\u308F\\u308A\\u305D\\u3046\\u3067\\u9762\\u767D\\u3044\\u3002 \\u6570\\u500D\\u306E\\u9045\\u5EF6\\u3082\\u8A31\\u5BB9\\u3067\\u304D\\u306A\\u3044\\u3001\\u304B\\u3064\\u3001\\u30B5\\u30DD\\u30FC\\u30C8\\u3057\\u305F\\u3044\\u30D7\\u30E9\\u30C3\\u30C8\\u30D5\\u30A9\\u30FC\\u30E0\\u304C\\u3059\\u304F\\u306A\\u3051\\u308C\\u3070\\u3001vendor specific \\u306A\\u30D5\\u30EC\\u30FC\\u30E0\\u30EF\\u30FC\\u30AF\\u3067\\u3082\\u3044\\u3044\\u304B\\u3082\\u3057\\u308C\\u306A\\u3044\\u3002\"}),(0,l.jsx)(e.p,{children:\"\\u3057\\u304B\\u3057\\u3001\\u65B0\\u3057\\u3044\\u30A2\\u30FC\\u30AD\\u30C6\\u30AF\\u30C1\\u30E3\\u304C\\u3067\\u305F\\u3068\\u304B\\u3001BlazeFace \\u306E\\u3088\\u3046\\u306B 7x7 \\u304C\\u3044\\u3044\\u3088\\u307F\\u305F\\u3044\\u306A\\u3068\\u304D\\u306B\\u3001\\u5B9F\\u969B\\u306B\\u65E9\\u304F\\u901F\\u304F\\u52D5\\u304B\\u305B\\u308B\\u3082\\u306E\\u306F\\u3069\\u308C\\uFF1F\\u3068\\u8003\\u3048\\u308B\\u3068\\u3001 Research\\u2192Deployment \\u307E\\u3067\\u306E\\u30A8\\u30B3\\u30B7\\u30B9\\u30C6\\u30E0\\u306E\\u5145\\u5B9F\\u5EA6\\u3001\\u30D9\\u30F3\\u30C0\\u30FC\\u306B\\u4F9D\\u5B58\\u3057\\u306A\\u3044\\u62E1\\u5F35\\u306E\\u65E9\\u3055\\u304C\\u898B\\u8FBC\\u3081\\u308B\\u306A\\u3069\\u3067 TFLite \\u3092\\u9078\\u629E\\u3059\\u308B\\u30E2\\u30C1\\u30D9\\u30FC\\u30B7\\u30E7\\u30F3\\u306F\\u5927\\u304D\\u3044\\u3093\\u3058\\u3083\\u306A\\u3044\\u304B\\u306A\\u3002\"}),(0,l.jsx)(e.p,{children:\"\\u5B9F\\u88C5\\u306F\\u3061\\u3089\\u898B\\u3057\\u305F\\u7A0B\\u5EA6\\u3060\\u3051\\u3069\\u3001\\u30AB\\u30FC\\u30CD\\u30EB\\u306E\\u5B9F\\u88C5\\u306E\\u4E2D\\u306B\\u3082 GpuType::ADRENO \\u3068\\u304B\\u3067\\u3066\\u304D\\u3066\\u3001\\u3084\\u3063\\u3071\\u308A\\u907F\\u3051\\u3089\\u308C\\u306A\\u3044\\u3088\\u306A\\u30FC\\u3068\\u3044\\u3046\\u611F\\u3058\\u3002\"}),(0,l.jsx)(e.p,{children:\"\\u5408\\u308F\\u305B\\u3066\\u8AAD\\u307F\\u305F\\u3044\\u8AD6\\u6587\\u3068\\u3057\\u3066\\u306F\\u4EE5\\u4E0B\\u3002\"}),(0,l.jsx)(e.p,{children:(0,l.jsx)(e.a,{href:\"https://research.fb.com/publications/machine-learning-at-facebook-understanding-inference-at-the-edge/\",children:\"Machine Learning at Facebook: Understanding Inference at the Edge - Facebook Research\"})})]})}function F(i={}){let{wrapper:e}=i.components||{};return e?(0,l.jsx)(e,Object.assign({},i,{children:(0,l.jsx)(a,i)})):a(i)}var C=F;return m(L);})();\n;return Component;"},"_id":"posts/201906/1907.01989.mdx","_raw":{"sourceFilePath":"posts/201906/1907.01989.mdx","sourceFileName":"1907.01989.mdx","sourceFileDir":"posts/201906","contentType":"mdx","flattenedPath":"posts/201906/1907.01989"},"type":"Blog","readingTime":{"text":"7 min read","minutes":6.035,"time":362100,"words":1207},"path":"posts/1907.01989","filePath":"posts/201906/1907.01989.mdx","toc":[]},"authorDetails":[{"name":"Tomohiro Kato / @tkat0","avatar":"/static/images/tkat0.jpg","occupation":"Softweare Engineer / Double Bassist","twitter":"https://twitter.com/_tkato_","linkedin":"https://www.linkedin.com/in/tkat0/","github":"https://github.com/tkat0","slug":"default","locale":"en","type":"Authors","readingTime":{"text":"3 min read","minutes":2.33,"time":139800,"words":466},"path":"posts/default","filePath":"authors/default.en.mdx","toc":[{"value":"2021-","url":"#2021-","depth":3},{"value":"2018-2020","url":"#2018-2020","depth":3},{"value":"2014-2017","url":"#2014-2017","depth":3},{"value":"Publications","url":"#publications","depth":3},{"value":"2022","url":"#2022","depth":4},{"value":"2021","url":"#2021","depth":4},{"value":"2020","url":"#2020","depth":4},{"value":"2019","url":"#2019","depth":4},{"value":"2018","url":"#2018","depth":4}],"tags":[]}],"prev":{"title":"neon-bindings/neonについて","date":"2019-07-06T21:30:00.000Z","tags":["rust"],"draft":true,"summary":"","slug":"neon-bindings","locale":"ja","type":"Blog","readingTime":{"text":"2 min read","minutes":1.18,"time":70800,"words":236},"path":"posts/neon-bindings","filePath":"posts/202006/neon-bindings.mdx","toc":[]},"next":{"title":"WebAssemblyでの機械学習モデルデプロイの動向","date":"2020-12-02T10:30:00.000Z","tags":["rust","wasm","deeplearning","mlops"],"draft":false,"summary":"本記事はMLOps Advent Calendar 2020の2日目の記事です。\nこの記事では、機械学習モデル（特にDeep Learning）をWasmでデプロイする周辺技術の動向や内部の仕組みをざっくりと説明します。","slug":"deploy-ml-as-wasm","locale":"ja","type":"Blog","readingTime":{"text":"18 min read","minutes":17.725,"time":1063500,"words":3545},"path":"posts/deploy-ml-as-wasm","filePath":"posts/202012/deploy-ml-as-wasm/index.mdx","toc":[{"value":"WebAssembly(Wasm) とは","url":"#webassemblywasm-とは","depth":2},{"value":"Wasm を機械学習で使うモチベーション","url":"#wasm-を機械学習で使うモチベーション","depth":2},{"value":"Wasm の機械学習モデルデプロイの動向","url":"#wasm-の機械学習モデルデプロイの動向","depth":2},{"value":"ブラウザへのデプロイ","url":"#ブラウザへのデプロイ","depth":3},{"value":"サーバーサイドへのデプロイ","url":"#サーバーサイドへのデプロイ","depth":3},{"value":"エッジデバイスへのデプロイ","url":"#エッジデバイスへのデプロイ","depth":3},{"value":"各プロジェクトの Wasm 対応状況","url":"#各プロジェクトの-wasm-対応状況","depth":2},{"value":"TensorFlow","url":"#tensorflow","depth":3},{"value":"TVM","url":"#tvm","depth":3},{"value":"WASI-NN","url":"#wasi-nn","depth":3},{"value":"ONNC-WASM","url":"#onnc-wasm","depth":3},{"value":"その他","url":"#その他","depth":3},{"value":"結論","url":"#結論","depth":2},{"value":"おまけ","url":"#おまけ","depth":2}]}},"__N_SSG":true},"page":"/posts/[...slug]","query":{"slug":["1907.01989"]},"buildId":"BbtclRdEExvhlqOtznToX","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>